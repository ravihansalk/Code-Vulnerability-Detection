{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import ast\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "file_path = 'clasification_Training.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "functions = df['input'].tolist()\n",
    "labels = df['output'].str.lower().apply(lambda x: 1 if x == 'vulnerable' else 0)\n",
    "print(len(functions))\n",
    "\n",
    "\n",
    "def preprocess_code(code):\n",
    "    code = re.sub(r'//.*|/\\*[\\s\\S]*?\\*/', '', code)\n",
    "    code = re.sub(r'\".*?\"|\\'.*?\\'', '', code)\n",
    "    tokens = word_tokenize(code)\n",
    "    return tokens\n",
    "\n",
    "preprocessed_functions = [preprocess_code(func) for func in functions]\n",
    "\n",
    "\n",
    "w2v_model = Word2Vec(sentences=preprocessed_functions, vector_size=100, window=5, min_count=1, workers=4)\n",
    "w2v_model.save(\"word2vec.model\")\n",
    "\n",
    "\n",
    "def tokens_to_embedding(tokens, model, max_len):\n",
    "    embedding = np.zeros((max_len, model.vector_size))\n",
    "    for i, token in enumerate(tokens):\n",
    "        if i >= max_len:\n",
    "            break\n",
    "        if token in model.wv:\n",
    "            embedding[i] = model.wv[token]\n",
    "    return embedding\n",
    "\n",
    "max_len = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    # Tune number of units in LSTM layers\n",
    "    model.add(LSTM(hp.Int('units1', min_value=32, max_value=256, step=32),\n",
    "                   input_shape=(max_len, w2v_model.vector_size), return_sequences=True))\n",
    "    model.add(Dropout(hp.Float('dropout1', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    model.add(LSTM(hp.Int('units2', min_value=32, max_value=128, step=32), return_sequences=True))\n",
    "    model.add(Dropout(hp.Float('dropout2', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    model.add(LSTM(hp.Int('units3', min_value=32, max_value=64, step=16)))\n",
    "    model.add(Dropout(hp.Float('dropout3', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "                  learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  \n",
    "    executions_per_trial=2,  \n",
    "    directory='hyperparameter_tuning',\n",
    "    project_name='lstm_tuning')\n",
    "\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=20, validation_split=0.1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best Hyperparameters: {best_hps.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "epochs = range(1, 21)  \n",
    "plt.plot(epochs, history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(epochs, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "\n",
    "plt.title('')\n",
    "plt.xticks(color='#B2BEB5',fontsize=11,fontname='Times New Roman')\n",
    "plt.yticks(color='#B2BEB5',fontsize=11,fontname='Times New Roman')\n",
    "plt.xlabel('Epoch',fontsize=11,fontname='Times New Roman')\n",
    "plt.ylabel('Accuracy',fontsize=11,fontname='Times New Roman')\n",
    "plt.xticks(epochs)  \n",
    "\n",
    "plt.grid(axis='y',linestyle='--', linewidth=0.2)\n",
    "\n",
    "ash_color = '#B2BEB5' \n",
    "ax = plt.gca() \n",
    "ax.spines['top'].set_color('white')   \n",
    "ax.spines['right'].set_color('white')  \n",
    "ax.spines['left'].set_color('#B2BEB5')   \n",
    "ax.spines['bottom'].set_color('#B2BEB5') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.legend(loc='lower right', fontsize=11, prop={'family': 'Times New Roman'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()\n",
    "\n",
    "\n",
    "trials = tuner.oracle.get_best_trials(num_trials=10)\n",
    "trial_scores = [trial.score for trial in trials]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(trial_scores) + 1), trial_scores)\n",
    "plt.title('Best Trial Scores')\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
